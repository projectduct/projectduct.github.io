<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Towards Culturally Grounded Approaches to Open Source Tool Interventions</title>
 
  <link href="assets/css/bootstrap.min.css" rel="stylesheet">

  <script src="assets/js/bootstrap.bundle.min.js"></script>
  <script src="assets/js/jquery-3.6.0.slim.min.js"></script>
  
  <link href="assets/font/kollektif-web/font-stylesheet.css" rel="stylesheet"> --> 
  <link href="assets/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/css/main.css" rel="stylesheet">


</head>
<body>


<nav class="navbar navbar-dark fixed-top bg-nav">
	<div class="container-fluid">
	  <a class="navbar-brand" href="#">Report: Towards Culturally Grounded Approaches to Open Source Tool Interventions</a>
	  <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"
	  >
		<span class="navbar-toggler-icon"></span>
	  </button>
	  <div class="collapse navbar-collapse" id="navbarSupportedContent">
		<ul class="navbar-nav">
  
	<li class="nav-item">
	  <a class="nav-link" aria-current="page" href="#index">Index</a>
	</li>
	<li class="nav-item">
		<a class="nav-link" href="#abstract">Abstract</a>
	  </li>
	<li class="nav-item">
	  <a class="nav-link" href="#acknowledgements">Acknowledgements</a>
	</li>
	<li class="nav-item">
	  <a class="nav-link" href="#background">Background</a>
	</li>
	<li class="nav-item">
	  <a class="nav-link" href="#methodology">Methodology</a>
	</li>
	<li class="nav-item">
	  <a class="nav-link" href="#findings">Findings</a>
	</li>
<!-- 	<li class="nav-item">
	  <a class="nav-link" href="#finding-1">1: The reality of Sino-Experience is absent from design and development processes.</a>
	</li>
	<li class="nav-item">
		<a class="nav-link" href="#finding-2">2: Free and Open Source Transparency Governance in Practice is Exclusionary and in tension with supporting high-risk users.</a>
	  </li>
	<li class="nav-item">
		<a class="nav-link" href="#finding-3">3: Validation of the Safety of Software Tools has not been standardized.</a>
	  </li>
	<li class="nav-item">
		<a class="nav-link" href="#finding-4">4: Funding structures incentivize new feature development and technical approaches over revision, maintenance, and core needs.</a>
	</li>
	<li class="nav-item">
		<a class="nav-link" href="#finding-5">5: Software interface internationalization does not account for the Chinese context.</a>
	</li>
	<li class="nav-item">
		<a class="nav-link" href="#finding-6">6: Prioritization of Engineering over Regional Expertise and Professional-Level User Experience Research</a>
	</li> -->
	<li class="nav-item">
	  <a class="nav-link" href="#Recommendations">Recommendations</a>
	</li>
	<!-- <li class="nav-item">
		<a class="nav-link" href="#Recommendations-1">Development of a Harm Reduction Framework for Feedback.</a>
	</li>
	<li class="nav-item">
	<a class="nav-link" href="#Recommendations-2">Increased Research Sharing</a>
	</li>
	<li class="nav-item">
	<a class="nav-link" href="#Recommendations-3">Regional Expertise and Professional-Level User Experience Research need to be prioritized over Engineering</a>
	</li>
	<li class="nav-item">
		<a class="nav-link" href="#Recommendations-4">Training for Targeted Software Stakeholders</a>
	</li> -->
		</ul>
	  </div>
	</div>
  </nav>
  <!--end navbar-->
  
  
	<div class="container-fluid">
  
		<img src="assets/svg/frontpage.svg">
			
		<div class="row">
  
			<div class="col-2">
			</div>
  
			<div class="col-8">
				<div class="reportCover">
					<h1 class="reportTitle">Towards Culturally Grounded Approaches to Open Source Tool Interventions</h1>
					<h3>Harm Reduction Based Approaches to Improving Technology for Chinese Human Rights Defenders</h3>
					<address class="reportContact">
						DUCT team<br>
						<a href="mailto:projectduct@proton.me">projectduct@proton.me</a><br>
					</address>
					<p>
						2022-2023<br>
						TLP:AMBER
					</p>

					<a href="/"><button type="button">Home</button></a> <br>
					<a href="report-1.html"><button type="button">Part 1: Voices from the Pipeline</button></a>

				</div>
  
			</div>
  
			<div class="col-2">
			</div>
  
		</div>
  
	</div>
  
  
  
  
  
	<div class="container-fluid">
  
  
		<div class="row">
  
		<hr class="pageChange" id="index">
  
			<div class="col-2">
			</div>
  
			<div class="col-8">
				
				<h1>Index</h1>
  
				<ul>
					<li><a href="#acknowledgements">Acknowledgements</a></li>
					<li><a href="#execSummary">Executive Summary</a></li>
					<li><a href="#introduction">Introduction</a></li>
					<li><a href="#approach">Approach</a></li>
					<li><a href="#findings">Findings</a></li>
					<li><a href="#needs">Needs and Challenges</a></li>
					<li><a href="#insights">Insights</a></li>
					<li><a href="#models">Collaboration Models</a></li>
					<li><a href="#recommendations">Recommendations</a></li>
					<li><a href="#conclusions">Conclusions</a></li>
				</ul>
  
  
			</div>
  
			<div class="col-2"></div>

<div class="container-fluid">
  
  
	<div class="row">
		  
		<hr class="pageChange" id="index">

		<div class="col-2">
		</div>
		  
		<div class="col-8">

	<h2 id="abstract"><strong>Abstract</strong></h2>
<p>This decade, the pandemic, accelerating technology, climate change
and shifting political and economic conditions have combined together to
produce new and urgent challenges across the world. However, the ways in
which human rights abuses, surveillance and other forms of state or
corporate violence manifest vary greatly on their local contexts.
Exploring everyday digital practices such as file-sharing, browsing,
network connectivity and other communication methods, this report
outlines the present day circumstances, material conditions and
challenges faced by human rights defenders, activists and other
politically engaged individuals and organisations within mainland China
and the wider Chinese diaspora.</p>
<p>Through a series of participatory interviews, observations and
reflections, this report finds that — like other areas of the world —
the arc of social justice and political safety is in steep decline in
this region. The configuration of Chinese governance and the decision by
successive Chinese lawmakers to intervene in the development of digital
technologies creates a unique set of challenges that are still poorly
understood by human rights defenders from beyond the Great Firewall. As
a result, the gap in understanding of software developers for the unique
and monolithic challenges faced by Chinese HRDs all but ensures these
individuals and organisations continue to experience heightened
risk.</p>
<p>Finally, this report offers some clear pointers for institutional
response to these challenges by documenting the activities and
perspectives around this unique geo-political region. Delivered as a
series of testimonies, the research focuses on the material realities of
individuals and organisations within the region, and presented to
support design and strategic decision-making for civic tech projects. At
the same time, this report does not offer a comprehensive snapshot of
the realities of participants on the ground. Equally, the findings
presented in this research do not represent an in-depth security audit
of any one tool, nor offer a value statement of the tools reviewed.
Instead, this report delivers quantitative insights and findings through
participant experiences, approaches and concerns to call for action to
combat technology-enabled abuse.</p>
<h2 id="acknowledgments"><strong>Acknowledgments</strong></h2>
<p>The research team wishes to acknowledge and thank each participant
who shared their experiences and expertise at their own risk. We are
committed to documenting and presenting their contributions as
accurately and respectfully as possible. We hope this report does your
work justice.</p>
<p>Thank you to our funders and partners whose support and feedback made
this work possible. If you have questions or wish to get more background
information, please feel free to contact us.</p>
<p>Research &amp; Report: DUCT team<br />
<a
href="projectduct@proton.me">projectduct@proton.me</a><br />
2023</p>
<h2 id="background"><strong>Background</strong></h2>
<p>The world has seen a serious rise of authoritarianism in the past 15
years, and the ever-increasing reliance on digital infrastructure
presents complex new challenges for dissidents of oppressive regimes.
China is no exception. From the cultivation of extra-national embedded
police forces, to the deployment of new and far-reaching National
Security Laws, to the extinguishing of Hong Kong governing autonomy, to
the human rights abuses of the country’s Uyghur population, China has
experienced an accelerating centralization of power and has grown to
wielding this power openly. For a country of 1.4 billion, this control
has necessitated the construction and administration of an enormous and
unique digital infrastructure apparatus.</p>
<p>No more has both the acceleration of central power and the
corresponding expansion of a supportive digital infrastructure been
visible than the emergence of COVID 19. Since the start of the pandemic,
the grip of the Chinese State on its population has only accelerated,
culminating in a public consolidation and solidification of power at the
CCP Congress in late 2022<a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>. Zero-COVID policies attracted
international attention and led to serious unrest in regions under
lockdown. Increased penalties for digital protest were observed,
especially triggered by acts such as citizen circumvention the “Great
Firewall.” The heightened tensions within the country, fueled by China’s
myriad of domestic issues such as climate change, real estate, social
demographics and debt crises, led to crackdown, disappearance and
persecution of human rights activists, journalists and lawyers.
Government addiction to secrecy and information control had dire
consequences for the flow of pandemic information, from case numbers to
whether a new novel coronavirus had been discovered at all. Across all
regions, the increase of power to law enforcement, security agencies and
the judicial system leads to both active persecution of human rights
defenders, and passive silencing of dissidents and protesters through a
chilling effect. </p>
<p>In all these instances, an unprecedented topology of networks,
sensors, firewalls and artificial intelligence maintains a dual-purpose
surveillance pillar looking inwards, and a digital iron curtain facing
outwards. Internet censorship, for example through the “Great Firewall”,
along with mass and targeted surveillance and large-scale disinformation
campaigns mean that citizens do not have access to information, cannot
exercise their freedom of speech, and are lacking basic guarantees of
secure communications and organization without state interference.</p>
<p>Although it is possible to recognize small parts of this broad
digital system through a non Sino (particularly Western) lens, the
inwards/outwards nature of the Chinese digital society leaves much
invisible for those beyond its borders. The international community for
which local human rights defenders rely upon do not have a complete
picture of the lived experiences of those on the ground. For example,
while it’s true that there are projects actively working to support
human rights defenders embedded in China’s deep censorship networks —
e.g. the <a href="https://www.torproject.org/">Tor Project</a>, <a
href="https://lantern.io/">Lantern</a>, <a
href="https://psiphon.ca/">Psiphon</a>, <a
href="https://shadowsocks.org/">Shadowsocks</a> — very little is known
about their effectiveness, adoption and use. Of course, part of this is
by design, as projects do not collect statistics on their users. As a
result, there has been a push to implement Human Rights Centered Design
and similar disciplines to help combat the inherent biases held by the
developers of these kinds of tools. In the case of the Sino-context,
these biases collide with an opaque country-wide infrastructure and
significant cultural differences to create a significant gap between
activists and defenders working on the ground and the technologists
developing intervention tools.</p>
<p>From both inside and outside of China, the human rights technology
ecosystem and its intended userbase continue to design and implement
countermeasures, while lacking qualitative and quantitative information
(e.g. what works, what doesn’t, when and where) as well as high-level
strategic and tactical recommendations specific to the Chinese context.
The gap between the organizations working on human rights in China and
the human rights technology ecosystem is quite large — exacerbating the
impact of the lack of local knowledge and context available to
developers and access, connection and understanding of the tools
available and how they can be applied to the nuances of the local
context.</p>
<p>Starting in 2020, this project set out with two objectives: (1) to
identity opportunities to network, support and cultivate learning
between activists in China, non-Chinese technologists and the global
internet governance community, and (2) to identify pathways of
recommendation to empower Chinese human rights defenders to participate
in broader international exchanges of information and collaboration.
This project had two phases: first, an ecosystem analysis via
stakeholder interviews to validate and expand on the needs,
opportunities and barriers to increasing networking and sharing across
this community; and second, building on the findings from the first
phase, pilot a research hub model to facilitate knowledge and resource
sharing among members of this community.</p>
<p>After completing the phase 1 ecosystem research, we determined that
there were significant barriers to implementing an information hub. In
response to this, we decided to explore a specific gap in knowledge by
exploring a pilot framework for facilitating feedback and information
sharing among members of the community focused on tools that enable
collaboration and information sharing. The phase 1 research report can
be found at: <a
href="https://projectduct.github.io/">https://projectduct.github.io/</a></p>
<h2 id="methodology"><strong>Methodology</strong></h2>
<p>This project had two phases: first, a stakeholder survey to validate
and expand on the ecosystem needs we identified, and second, exploring a
pilot framework for facilitating feedback and information sharing among
members of the community. Our methodology for the second phase was
informed by the outcomes of the first phase; During our phase one
research, we conducted needs finding interviews with 21 participants
from the ecosystem. To summarize those findings, <em>the existing
security software applications do not adequately meet the needs of
high-risk defenders operating in China.</em> This is a compounding
issue, where the more urgent the situation, the more existing civil
society software fails to accommodate these at-risk individuals.
Specifically:</p>
<ul>
<li><p>Activists on the ground lack basic infrastructure and technical
support systems that can be accessed in other regional
contexts.</p></li>
<li><p>Technologists lack user data, use cases, and other user-specific
feedback from human rights defenders within the region. This is caused
both by the opaque state structures that obscure these observations, but
also significant language and cultural barriers and safety
concerns.</p></li>
<li><p>Technologists demonstrate an incomplete or biased understanding
of situations faced by human rights defenders in China. Technologists
are not aware of region-specific requirements and face challenges in
testing and disseminating their tools.</p></li>
<li><p>All of this amplifies dangers or precarity, especially during
crisis situations, such as protest, natural disaster or
crackdown.</p></li>
</ul>
<p>Building on that research, we set out to explore ways to improve the
gap between the region-specific requirements and challenges around the
tool development, to address the lack of basic communication and
collaboration infrastructure.</p>
<p>In the second phase of this project, we used multiple methods —
qualitative interviews, scenario exercises, and an evaluation rubric —
to identify and assess tools, understand the needs of human rights
defenders, and assess the understanding of these needs by human-rights
focused technologists and designers. These methods enabled us to conduct
qualitative analysis to grounded in the experiences shared by the
participants, and the broader understanding of the challenges of
region-specific requirements and tool development.</p>
<p>To meet the project’s larger goal of developing digital networks, we
wanted to explore a risk mitigation and harm reduction framework that
might enable safer feedback processes. To explore this, we engaged
participants at multiple risk levels, and comparing the feedback shared
by low, medium and high-risk participants. Finding ways to de-risk
engagements with HRDs in China and improve tools in impactful ways would
enable not only more feedback to be possible, but also it would
strengthen communication channels between software stakeholders and
high-risk individuals operating in a high-surveillance state, and
ultimately increase the usefulness and impact of security-minded tools
in China.</p>
<h3 id="research-participants"><strong>Research
Participants</strong></h3>
<p>To achieve a representative data set, the researchers met with
various software stakeholders and end users with varying risk levels.
The most at-risk group identified as human rights defenders. These
groups were divided by their area of expertise:</p>
<p><u><strong>Impacted Community/End User groups<br />
</strong><em>Total</em></u><em>: 10 end user participants. 60% percent
were considered high-risk</em></p>
<ul>
<li><p><strong>Group 1 (Defenders):</strong> End users with varying risk
levels, including high-risk users, including human rights defenders and
lawyers working on a range of LGBT, women and migrant worker rights,
and</p></li>
<li><p><strong>Group 2: (Low/Medium Risk)</strong>: End users with low
to medium risk, e.g. people with connections to the region and varying
levels of expertise in the region.</p></li>
</ul>
<p><u><strong>Software stakeholder groups<br />
</strong><em>Total</em></u><em>: 5 developer &amp; designer
participants</em></p>
<ul>
<li><p><strong>Group 3:</strong> Software developers, including
individuals or entities who develop technology interventions focused on
supporting human rights use cases, e.g. civic tech and open source
digital security, secure communications or other projects for which
human right defenders are considered a user demographic.</p></li>
<li><p><strong>Group 4:</strong> Software user experience designers,
including individuals or entities who design interfaces for or provide
translation and documentation for civic tech and open source digital
security, secure communications or other projects for which human right
defenders are considered a user demographic.</p></li>
</ul>
<p>In assembling a cohort of participants, we sought to identify a broad
range of potential risk, ensuring that low or no risk software
stakeholders and human rights defender participants were represented
alongside their high-risk colleagues.</p>
<p>The findings from Phase 1 of this project’s research confirmed
Chinese defenders are rightfully reluctant to meet with foreigners.
Given the scope of the resources for this work, we acknowledge that
there is more diversity of Chinese defenders than we were able to engage
with as part of this study, and that due to the risk of meeting with
foreigners, we can assume that there are more high-risk defenders that
did not feel comfortable participating in the research.</p>
<h3 id="qualitative-interviews"><strong>Qualitative
Interviews</strong></h3>
<p>The researchers invited participants to a set of qualitative
interviews. Questions were presented depending on the context: as 1-on-1
or group discussions and other formats as needed. Broadly speaking, the
questions covered <em>background context</em> and <em>use cases.</em>
The line of inquiry documented in this Methodology section were not
asked in order, and were re-ordered or presented as per the dynamics of
each participation session.</p>
<p><u>Background context — User needs</u></p>
<ul>
<li><p>Confirm and clarify high-risk defenders’ needs around file
sharing and storage</p></li>
<li><p>Assess defender representative groups’ receptiveness to software
applications selected for having some potential for meeting file sharing
and storage needs</p></li>
<li><p>Identify the gaps between defender ideals for file sharing and
storage and the existing solutions.</p></li>
<li><p>Identify areas in which low-to-no risk stakeholders are able to
provide accurate user insight comparable to that of identified needs of
high-risk individuals.</p></li>
</ul>
<p><u>Background context — Development Process Questions</u></p>
<ul>
<li><p>Identify gaps between software developers’ perceptions of
pressing security needs and high risk defenders’ actual needs for this
region</p></li>
<li><p>Identify current resources and approaches used by software
developers to select security models and associated software
architectures</p></li>
<li><p>Identify if and how software developers have any “obligation” to
test validity of security models and architect to meet security needs of
high risk defenders in this region</p></li>
<li><p>Identify if and how software developers have any obligation to
meet the needs of high risk defenders</p></li>
</ul>
<p><em><u>Use Case</u></em></p>
<p>Participants were asked questions about a specific use case of
digital technologies for the purposes of either completing their
objectives (in the case of human rights defenders) or
designing/communicating with users (in the case of software engineers
and designers). Participants were asked to speak about this specific use
case within their specific contexts.</p>
<p>Referring to the previous phase of research, we identified five
possible use cases to consider:</p>
<ul>
<li><p>Circumvention, circumvention, circumvention (first, foremost, and
always in China)</p></li>
<li><p>Chat apps—not blocked and with a strong encryption and apt
security model</p></li>
<li><p>Video or voice apps—not blocked with a strong encryption and apt
security model</p></li>
<li><p>Secure, hosted file storage—not blocked with strong encryption
and apt security model</p></li>
<li><p>Secure hosted file sharing—not blocked with strong encryption and
apt security model</p></li>
</ul>
<p>The research methodology focused on a single “pressing need” — in
this case, of file sharing — as a way to focus the use cases for the
research. While this did not reduce the broad range of human rights
defender participants, it did narrow the software engineer and designer
participant groups, as not all members of these groups focus their
practice on the secure exchange of files. Despite this, the methodology
considers file sharing to be a globally ubiquitous and integral software
user feature for which there is not a secure option available for the
region, and which the absence of creates a critical security gap.</p>
<p>In preparing for and speaking with participants, the researchers
formally categorized threats, risks, desired software and security
features. The security choices inherent in the software we selected for
this research, and some of the defender user responses were also
evaluated so that initial findings could be presented to the software
stakeholders for their response. In addition, we utilized a case study
research approach— presenting real world context in order to elicit
deeper insight on a complex issue—to gain an understanding of the
security thinking and approaches software stakeholders had in regards to
file sharing and storage.</p>
<p>Based on time and resources this research focused on file sharing and
storage needs, and therefore should not be understood as an attempt to
be prescriptive or definitive on all user needs and experiences for
high-risk individuals operating inside or outside China.</p>
<h3 id="assumptions-scope"><strong>Assumptions &amp; Scope</strong></h3>
<p>The complexity of software, of geopolitics, of cultural barriers and
of individual and local lived experience all combine with facilitator
biases to produce limits to any research project. In broad strokes, the
design of the research assumes that limiting the scope to defender
communities and their software needs is necessary so that we do not
become lost in the scale and diversity of a nation the size of China.
This, of course, must be acknowledged against the reality that varying
socio-political factors exist, and that the policies and actions taken
by China’s current regime can impact differently those members of
non-China regions and targeted ethnic groups (e.g., Hong Kong, Tibet,
etc.).</p>
<p>This research is focused on the needs and security concerns of
mainland Chinese and Chinese diaspora human rights defenders. This is –
of course – a somewhat arbitrary scope boundary, as the activism by
human rights defenders does not always focus entirely on issues within
their local scope. Regardless, the research considered non-China regions
and minorities as out of scope for this phase of the work. Additionally,
the research does not attempt to answer needs for general Chinese
populations (e.g., access to blocked media, etc.)</p>
<p>To comply with the funding schedule, the research considered other
technology use cases and user needs as out of scope for the this current
phase This research and its findings are not an assessment of all tools
that might be considered “security” or "Internet Freedom” focused. This
project did not conduct security audits of code or actual
implementations and did not formally investigate funding or
organizational structures.</p>
<p>As part of the research methodology, the researchers interrogated and
documented additional assumptions:</p>
<ul>
<li><p>Human rights defenders and their communities operate on trust and
consist of many networks with varying degrees of safety needs;</p></li>
<li><p>Technologists lack information about and understanding of
region-specific requirements, and face challenges in testing and
disseminating their tools.</p></li>
<li><p>Security applications or popular applications purposed for
activist work do not meet high-risk individuals’ most pressing needs in
this specific region.</p></li>
<li><p>Activists in this region lack basic infrastructure and technical
support systems — especially in crisis situations.</p></li>
</ul>
<p>Finally, this research leverages the user research guideline that
most issues can be identified by 3-5 participants, and beyond that there
are diminishing returns.<a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a></p>
<h2 id="findings"><strong>Findings</strong></h2>
<p>The free exchange of information and data in binary files remains a
fundamental decentralizing power for communities. The challenges
associated with this are different for different people and communities.
This research validated the hypothesis that Chinese human rights
defenders have unmet pressing needs for file sharing and related network
activity. While this is broadly true in many contexts, the lack of
baseline secure infrastructure tools is critical, particularly for
collaboration and communication needed to build communities and
networks.</p>
<p>The research found that current approaches for software development,
management, support and architectural models are in tension with
China-based defenders security needs or ways of operating. This, in turn
creates dangerous circumstances that erodes trust. Due to the
existential nature of these threats and cultural tensions and biases of
toolmakers, it is not enough to simply “up-skill” software stakeholders
and or establish safety protocols. Similarly, prioritized user
experience activities supported in the public interest security space
are not adequate to meet the complexities of this region. In addition,
the user experience activities that have generally been supported
to-date in the public interest security tool space are not adequate to
meet the complexities of this region.</p>
<p>In general, the research found:</p>
<ul>
<li><p>Understanding the lived experience of the threat environment of
China is complex and overwhelming. Much of this is due to systemic
inter-generational cross-cultural differences and language barriers, but
also heightened by more recent geo-political tension and the
over-reliance on the dominant assumptions of Western open source and
civil society technology culture and values.</p></li>
<li><p>Intersectional knowledge is key to translating how the social and
political context combine with the technical infrastructure and
technology in use, and is in short supply in the broader community.
which is connected to the current inadequate analysis of Chinese HRDs
needs.</p></li>
<li><p>Many stakeholders depend on advice from presumed experts that
lack contextualized knowledge of the specific needs of the
region</p></li>
<li><p>Internet freedom funded tools are focused on addressing needs by
introducing increased security complexity, rather than strengthening the
security of more standard tools—at the expensive of missing ubiquitous
user needs.</p></li>
<li><p>Software stakeholders do not hold the institutional knowledge,
connections or recognize the expertise needed to appropriately manage
security with high-risk defenders inside China.</p></li>
<li><p>Safety and security of software is not validated, nor assess in
standard ways.</p></li>
<li><p>Engineering is prioritized and better resourced than regional
expertise or bridging capacity, such as user experience
research.</p></li>
</ul>
<h3
id="the-reality-of-sino-experience-is-absent-from-design-and-development-processes-in-the-international-public-interest-tech-ecosystem-leading-to-misalignment-in-approaches-to-addressing-the-more-pressing-security-priorities-of-the-region-with-technical-security-and-infrastructure-interventions">1:
The Reality of Sino-Experience is absent from design and development
processes in the international public interest tech ecosystem, leading
to misalignment in approaches to addressing the more pressing security
priorities of the region with technical security and infrastructure
interventions</h3>
<p>The Chinese digital landscape is influenced by three core trends that
make it a unique context that demands that existing systemic biases be
examined. Broadly these are:</p>
<ul>
<li><p>A population with extremely high technical literacy;</p></li>
<li><p>A current authoritarian regime that centers technology within its
means of control; and</p></li>
<li><p>A well-funded and frictionless State apparatus that is able to
implement manifest power via technical controls and new infrastructure
with speed and precision.</p></li>
</ul>
<p>Understanding the user needs of the region requires understanding the
security needs well enough to be able to approach technical intervention
design or to do discovery work safely, e.g. engaging knowledgeable end
users while not putting them at risk. Some of this knowledge gap can be
attributed to issues of news and media coverage, which is of course
influenced strategically<a href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a>. In Western Media, the focus of
media tends to be tensions between China and Taiwan, Hong Kong and
China, or recently the Uyghur communities in Western China, leaving out
the nuance and complexity of the country as a whole. Chinese defenders
are placed at significant risk having a conversation with a foreigner.
The risks become almost insurmountable if it is also easily identifiable
that a foreign contact is associated with an NGO, non-profit, or
“freedom” seeking organization. High-risk Chinese individuals rightly
will not risk speaking directly with individuals that do not have
experience in the region. This creates a significant knowledge gap in
the region, one heightened by international paranoia from state reach
beyond the borders of China. These realities magnify the harms, while
simultaneously creating a chilling effect for knowledge sharing with
at-risk groups.</p>
<p>At the same time, those who take the risk to speak with the
international community are frustrated with what they perceive as an
inadequate response. As a result, the risk of speaking with a foreign
individual when there is little to no guarantee of an outcome that could
benefit their networks is too great. This is acutely felt at a systemic
sociological level within the human rights defending community, and
alongside non-Chinese biases and structures of software governance,
creates a cyclical systemic failure.</p>
<p>As a result, it is more common that software and technical
interventions are designed with little to no understanding of the
reality of the Sino-experience, and the resulting products are
insufficient to address the needs. More so, this gap has significant
implications for equitable access to a free internet.</p>
<p>Often, the approach is to leverage relationships in the broader
region as proxies for the Sino-experience. This is a frequent practice
for design and development of technology when access to the impacted
community is not possible. The challenge in this case is that the
Sino-experience and context is extremely unique, and while there is a
broad community with a surface-level understanding, it is significantly
different in ways that are not known by the international public
interest technology community. As a result, even the pressing need for
secure file sharing and storage are believed by the tech community to
have been met, when for the impacted community this is not the case.
This points to the fact that the need is simply not understood by
engineers and designers. Most understanding of the need is grounded in
concepts and strategies that are appropriate in other contexts.</p>
<p>This lack of awareness and understanding has significant impacts,
e.g. developer participants proposing solutions that would increase
security problems for people on the ground in China. The developer
participants were very aware of many types of technical security threats
that are important to consider, e.g. packet sniffing and blocking, and
as a result overlooked ubiquitous feature needs, e.g. non-self hosted
cloud storage and sharing.</p>
<p>Designer participants commonly stated that they could not adequately
understand the “security” issues, which indicates that the culture of
secure systems designs for software is broadly considered the
responsibility of engineering, rather than a broader
organizational-culture requirement. Usable security and the role of
design is still an emergent practice, even for practitioners focused on
products designed as security interventions. Additionally, extending
this security knowledge to the practice of engineering and design is not
common place. The designer and developer participants did not consider
themselves at risk, which contributes to their understanding of safely
navigating interactions with people in-country and in-region.</p>
<p>Examples of risks that were not considered were:</p>
<ul>
<li><p>Relying on insecure, non-anonymous contact with the software
stakeholders in order to obtain an instance of the software to
use</p></li>
<li><p>Creating funding or pay trails as necessary metadata to enable
use of software</p></li>
<li><p>Relying on Public user support/ticketing systems for bug triages
and not providing secure, anonymous user support channels</p></li>
<li><p>Relying on network tools that generate unique signatures that
paint targets on activists (such as Tor, VPNs or other ‘unusual’ network
traffic)</p></li>
</ul>
<p>Given these gaps in security knowledge, these software projects
tended to:</p>
<ol type="1">
<li><p>rely on security training to inform their user experience
research;</p></li>
<li><p>Rely on regional partners, organizations and use cases;</p></li>
<li><p>Individuals living in or from China but whom are not targeted and
do not perform defender work (e.g., software consultants, or Chinese
ex-pats living outside China)</p></li>
<li><p>employ formal UX efforts almost entirely at late stage user
experience work to resolve what were perceived as “adoption” problems
with software; and</p></li>
<li><p>use their late stage UX professional-level graphical interfaces
on tools that in many ways were still in user and security feature
infancy.</p></li>
</ol>
<p>This discrepancy is institutionalized within higher-risk, social good
software development culture. Participants indicated an over reliance on
user training and software maintenance aspects of software development
processes as a substitute for richer software user experience research
(e.g., citing the prioritization of “bug” or “feature” tickets from
trainers or users as the “roadmap” for meeting needs). For example, when
asked how one organization tests their security assumptions, they
stated, <em>“we rely on in-person training and online training, which
have components of that, which we put into our design work.”</em> In
sensitive contexts, this places the burden of safety on the end
user.</p>
<h3
id="free-and-open-source-transparency-governance-in-practice-is-exclusionary-and-in-tension-with-supporting-high-risk-users"><br />
2: Free and Open Source Transparency Governance in Practice is
Exclusionary and in tension with supporting high-risk users</h3>
<p>Software development stakeholders, particularly open source
advocates, regularly operate under a narrowly defined set of shared
principles that do not adapt to the realities of experiences of high
risk users in this region. These issues extend through transparency,
collaboration and open community governance; and many common community
contribution and software maintenance patterns have emerged out of these
community spaces. All of these have major drawbacks that raise the
perceived or actual risk levels for at-risk users in this context.</p>
<p>For software engineers and designer participants, this practice is
not merely a tactical position, the act of creating public interest
security software is an overt commitment to the open source community
ethos but also the ideals common to internet freedom and human rights
spaces. In more democratic societies, the source code ethos of
transparency forms a core foundation for security assessments. Several
of the software stakeholder participants made direct references to such
philosophical underpinnings, framing the assessment and verification of
the safety of tools as a task for adopters and end users: <em>“Anyone
can grab the source and host and run anywhere…it gives transparency in
this way.”</em></p>
<p>Setting aside the technical literacy challenges this expectation
necessitates, open source projects, user support, QA and feature
roadmaps also adhere to an ethos of transparency, or “working in the
public.” “Working in the public” can take a variety of forms, but for
many projects, this includes public visibility of code repositories,
public support and feature discussions. Inherent in the openness of
these systems is the use of visible, public identity through needing an
account on these platforms to engage with the product teams. From the
“working in the open” value and practice space, this openness is an
opportunity to build community and for individuals to build trust and
rapport through participation. Software engineer and designer
participants did not identify nor connect how these practices around
transparency could be a direct threat to high-risk end users based in a
broad or encompassing panopticon. When asked if such approaches to user
support, communications of user needs, and other such matters could be
done in protected spaces, participants often downplayed this from a
structural perspective. One participant with more familiarity of the
region and threat model noted, <em>“first tier public support is
public,”</em> and a user requiring additional privacy or security could
<em>“just ask”</em> if they wanted more secure communications.</p>
<p>Software stakeholders readily recognize that an inability to connect
with Chinese defenders is an issue for meeting these defenders needs.
However, such stakeholders are reticent to recognize that the fully
transparent, and “open” or semi-open approach to software support,
development and feature prioritization is an obstacle to supporting such
defenders.</p>
<p><em>Such reticence is not malicious or out of a disregard of concern
for people in this region.</em> In fact, to the contrary. All software
stakeholders that participated in this project demonstrated a
significant commitment to or interest in serving these communities. Yet,
the disconnect remains, stemming from incompatible and fundamentally
opposing cultural contexts. It is difficult for individuals raised and
operating in open societies to grasp the scale of surveillance that
those in this region experience and how that translates into reality. As
a result, they cannot readily connect and understand that their ways of
operating might be a blocker to learning about needs of defenders in the
region.</p>
<p>The democratic methodologies employed by software stakeholders’
(e.g., upvotes, public repos, community driven open source, etc.) are
informed by cultural values that stand for transparency, collaboration,
and open community. These values are not unique to the stakeholders and
also align with those of the “Internet Freedom” community. The results
of these values speak for themselves, having proven to have been a
foundational theory of change in many human rights situations. The
values and their practices have reinforced over time, disincentivizing
analysis and critical evaluation in new or unfamiliar cultural or
political contexts.</p>
<h3
id="validation-of-the-safety-of-software-tools-has-not-been-standardized">3:
Validation of the Safety of Software Tools has not been
standardized</h3>
<p>If the technology that serves human rights defenders is built on
openness, democratic governance and transparency, the lacking approach
to user safety and the validation of the effectiveness of software tools
to protect those who use them are glaring systemic oversights. Central
to understanding why this is happening is a key finding from this
research: Software engineers and designers have no requirement to test
their security models’ validity or to meet user needs.</p>
<p>The participants who build secure tools were asked to reflect on
their practices when assessing their security design practices with
at-risk users. Some participants referenced learnings from other
projects in nearby regions, learnings from trainers, community
practitioners, design/research practitioners they have established
relationships with, but none of the participants spoke to an example in
which they directly validated or tested their security model’s
assumptions with individuals in this region. The most common reason
cited for this was an inability to connect or communicate with in-region
individuals or entities who may be connected with in-region individuals
and groups. The stakeholders cited an inability to connect with
in-region high-risk individuals as an obstacle to complete this form of
testing. In thinking about ways to address this gap, participants
discusses ideas about simulations, automation, and various other
technical approaches. A common refrains from participants reflected on
this gap, saying, <em>“This is very tricky. We don’t really know how to
test these assumptions.”</em></p>
<p>Participants confirmed that testing whether a security model was
adequate or more general users’ needs had been met for China users, was
solely self-audited and evaluated. Outside of self-evaluation,
participants shared that they frequently turn to existing relationships
for feedback on the design of security features, e.g. starting from
communities, groups or individuals that have some intersection of
characteristics with the Chinese threat model. As one participant noted
for China in particular: <em>“[this research group] has been the closest
contact so far on something like this.”</em> Efforts for inclusion
tended to be opportunistic: <em>“If we can find people with the capacity
to participate in app design then that becomes very valuable.”</em></p>
<p>Additionally issues of safety validation and the lack of responsible
critical review of tools as process includes - and is affected by -
operational practices and costs. Though not directly raised in
interviews with software and design stakeholders, participants did bring
up challenges around incentives/compensation for participants in
software feedback and challenges around project structures and
organizational models. Our software and design participants came from a
range of team structures, e.g. multi-organization open source projects
as well as companies with different departmental focuses, which suggests
that there are many different organizational process complexities to
consider, e.g. standard procedures for participant compensation or data
handling versus adapting their processes to meet all of the security
needs for one region. .</p>
<h3
id="funding-structures-incentivize-new-feature-development-and-technical-approaches-over-revision-maintenance-and-core-needs">4:
Funding structures incentivize new feature development and technical
approaches over revision, maintenance, and core needs</h3>
<p>From our conversations with high-risk user participants, it was clear
that they felt that some of the basic needs and issues they raised have
already been communicated or shared with teams, and are “known issues,”
and yet have not been prioritized or addresses by software development
teams. Participants from software development and design teams referred
to specifically funded projects and initiatives that were guiding the
priorities of their work, and challenges around navigating those
commitments, e.g. misalignment of resources, lack of resources, no space
for emergent/responsive priorities, tight time lines to account for
feedback engagement processes, and agency in driving the planning and
implementation processes. Participants from software development and
design teams also noted that the funded projects and efforts were
frequently defined around new ideas or features, rather than on
maintenance or improvements to existing functionality, making it
challenging for teams to prioritize improvements that could not be
connected to “state of the art” or advanced techniques to address the
Chinese context. Gaps were also identified around long terms costs of
developing software, such as hosting a service, maintenance, including
responding and addressing vulnerabilities, device support and testing,
or usability improvements.</p>
<p>Sustainability for these software development projects is not
commonly addressed. Teams are expected to find ways to fund their
project for the long-term, which contributes to challenges reaching more
mature products and practices. Many projects have been considering
sustainability models that enable direct support from end users, e.g.
sustaining donations or pay models, but those require both engineering
and design effort to implement as well as security considerations for
payment models, introducing additional complexity particularly for
highly monitored and surveilled regions like China where the data trail
for payment is a make or break security threat.</p>
<p>From our conversations with participants, it was clear that a large
gap exists between human rights defenders and software stakeholders
around security prioritization. The security threats that have the
highest probability of occurrence or that would result in the most
malignant risks for individuals in this region were under recognized.
Some examples of these factors include:</p>
<ul>
<li><p>Inadequate or lack of encryption;</p></li>
<li><p>Security models that assumed self-hosting as a means of
increasing security;</p></li>
<li><p>Security models that relied on ephemeral strategies, such as
disappearing messages;</p></li>
<li><p>Security modes that depend on identity systems such as phone
numbers, emails, or other platforms;</p></li>
<li><p>Security models that depend on establishing a connection through
another channel ;</p></li>
<li><p>Security models that depend on frequent or ‘noisy’ networking,
such as Tor.</p></li>
</ul>
<h3
id="software-interface-internationalization-does-not-account-for-the-chinese-context">5:
Software interface internationalization does not account for the Chinese
context</h3>
<p>Internationally, we are entering an era where the culture that
employs a strategy of high-financial- and labor-cost prototyping with
high failure rates <em>must</em> give way to a clear, deliberate
building of complementary tooling that is designed to succeed and be
maintained in the longer term. The short-term priorities of funders and
open source software culture deprioritises long term costs and sets up
even successful implementations for failure. For example, long-term
hosting, internationlization and maintenance costs are regularly not
supported. Groups are expected to find ways to fund their project for
the long-term meaning they seldom making it out first beta. This
represents a paralysis of long term thinking, that makes demands of both
software stakeholders and human rights defenders whose time is limited
and requirements broad and urgent. As one software stakeholder quickly
noted, “hosting costs could skyrocket” when discussing meeting a
particular defender target groups’ needs (though this stakeholder was
also able to identify 2-3 potential means of controlling this as
well).</p>
<p>Inadequate software internationalization itself adds a layer of
complexity and unsuitability for proposed software solutions that is
frequently deprioritized by short-term funding strategies. In sensitive
or pressing security contexts. Participants described a inadequate
internationalization creates uncertainty and distrust, and increases the
likelihood of a user making a mistake, which is of course heightened for
at-risk users. This reality was readily recognized by all stakeholders
and represents an obstacle the community has the experience and
resources to readily resolve.</p>
<p>Yet, investing in localization, training, and adoption outreach to
advocate for use of tools by at-risk communities is a high-resource
high-risk investment; an investment that is not worth it if it if tool
is not usable, not ready, or will not be able to sustain itself within a
short time frame.</p>
<p>As such, software applications often won’t even be considered by
defenders if it does not meet basic usability interface patterns. Basic
usability is expected as a baseline. Unpolished software can be
perceived as unfinished, and therefore not to be trusted yet. It is
common place that a technique or application that worked last week
routinely will not work the following. And any generalized security
feature sets—that have reached the stage of general understanding and
adoption by a larger global security community— already do not or soon
will not work within the region.</p>
<p>This means <em>late stage user experience work</em>— e.g. high
fidelity graphical interface design work, which is optimized for
usability and pleasing experience to encourage adoption—<em>is not the
most pressing user experience work needed</em> for this region. And
<em>relying on generalized security and user analysis does not support
defenders’ needs</em> in region for any sustainable length of time.
Instead, it is deeper research and analysis —of the direct needs of the
region and how that translates into a particular piece of software—that
is most needed.</p>
<h3
id="prioritization-of-engineering-over-regional-expertise-and-professional-level-user-experience-research">6:
Prioritization of Engineering over Regional Expertise and
Professional-Level User Experience Research</h3>
<p>The culture of extractivist research and institutionalization of
shared, on the ground expertise was prevalent in – but not unique to –
this project. For example, this research project was not initially
designed with participant stipends. This is due to a number of factors,
e.g. 1) it was not at first recognized that defender representatives
whom might work in region should be compensated for their time and work
on the project (e.g,. sharing their expert knowledge, arranging user
meetings; reviewing security protocols; etc.); 2) it was not clear that
there could be a safe way to compensate participants, and 3) it is can
be hard to make a case for paying participants when developing grant
budgets. This is another example of the ‘us vs them’ tension felt by
participants that fuels distrust and a lack of faith in broader
international community’s ability to safeguard the well-being and
livelihoods of Chinese human rights defenders.</p>
<p>Of course, issues of extractivism or colonialist dealings with
societies by civil society funders and institutions is a systemic issue.
Software stakeholders also routinely expect NGOs and activists’ networks
(i.e., the ones taking the most risk in this work) to participate in
software development cycles without any compensation. The safety or
precarity of user health or livelihood is not accounted for – even if
the projects’ key performance indicators and obligations to funders
relies upon successful adoption from high risk individuals. There is
instead a cultural assumption that – similar to Open Source movements –
the high-risk user donates their time and labor as a speculative
investment in software that might support their risk profile and make
their work safer, despite no guarantees for delivery, long term
maintenance or project success</p>
<p>Conversely, however, it is assumed software engineers <em>will
be</em> financially compensated first if there is any money going around
(it should be noted this is not <em>as</em> readily assumed for user
experience professionals). This disparity is clearly understood and
noted by at risk users, and fuels further distrust. However, while the
research can support that such an imbalance exists, it cannot and does
not attempt to answer the direct causes. Yet, we do highlight that the
existing imbalance does have a direct relationship to the scale of
impact that can individually and collectively be achieved by all
software stakeholders.</p>
<p>The solutions around remuneration are not as simple as earmarking
sums of money. There are significant political ramifications for
financial compensation as markers for collaboration against the State,
and safely paying high-risk individuals remains a complex affair.
However, it does not for the assumptions that only software stakeholders
should be compensated; as NGOs and non-profits working in regions, and
defenders do have the requisite regional expertise.</p>
<p>This ultimately has the affect of prioritizing and valuing
engineering over regional expertise, contributing to the strained
relationships that exist between international NGOs and HRDs on the
ground.</p>
<h2 id="recommendations"><strong>Recommendations</strong></h2>
<p>It is clear that a dramatic rethink is necessary before proceeding
with attempts to support at-risk users in the region. To begin
addressing the issues raised in this report, In order to reconcile, it
means the public interest software stakeholders and funders eco-system
must first accept <em>community building is not the problem to solve.
However,</em> the underlying intention of such a
community<em>—increasing the usefulness and impact of security-minded
tools in China—is still achievable.</em> This is reflected in both the
unmet user needs and the broader desire for user interaction and
consultation despite negative experiences with software stakeholders.
China is a country with a population with extremely high technical
literacy, coupled with an authoritarian regime that centers technology
within its means of control. These facts are playing out against the
tech arms race of the 21st century—the speed and scale at which the
current regime is able to implement its technical controls can be
breakneck.</p>
<p>The challenges identified in this research also confirms that two
immediate issues need to be addressed as a core response to the overall
gap between software stakeholders and high risk users:</p>
<ul>
<li><p>Defenders working inside China do not and should not speak
directly to foreign software stakeholders.</p></li>
<li><p>Software stakeholders need opportunities for direct feedback from
Chinese defenders to improve their software’ applicability to the
region.</p></li>
</ul>
<p>As covered in our first report, there are many gaps to be addressed
before building a more connected <em>community could even be considered.
However,</em> the underlying intention of such a community<em>—to
increase the usefulness and impact of security-minded tools to protect
human rights defenders in China—is still achievable.</em> To that end,
we recommend<em>:</em></p>
<ul>
<li><p>A framework to enable the public service security software
community to increase the usefulness and impact of security-minded tools
in China increase while maintaining the safety of high-risk
defenders;</p></li>
<li><p>Increased research sharing in small groups and with santized
research shared more broadly;</p></li>
<li><p>Prioritization of regional expertise and a focus on
usability;</p></li>
<li><p>Targeted training of certain software stakeholders that could
increase impact of security solutions in this region;</p></li>
<li><p>Recommendations for activities and tools that can be introduced
in the funding process that could also increase impact and
accountability back to high-risk communities’ needs;</p></li>
</ul>
<h3
id="development-of-a-harm-reduction-framework-for-feedback">Development
of a Harm Reduction Framework for Feedback</h3>
<p>Increasing the usefulness and impact of security-minded tools in
China requires specialized, in depth usability testing for such software
is to be successful. However, this also involves—on some level—getting
direct feedback from defenders working in the region. To do this
securely we believe requires regional knowledge, connections and other
expertise that do not adequately exist in the public interest security
software ecosystem.</p>
<p>Therefore, we propose a framework that can enable secure technical
testing and qualitative, participant driven testing. To achieve this, we
need to be assess what type of feedback, research, or testing is needed
and explore ways to get that feedback. Our recommendation is based on a
model of harm reduction, where we design the process so as to lessen the
potential negative consequences to impacted communities, i.e. in this
region, reserve contact with on the ground defenders for the most
critical questions that only they can support and answer, and when
connecting with defenders on the ground, leveraging necessary protocols
to protect the defender from the risk of being connected with an
international NGO or freedom initiative.<br />
<br />
This concept was only able to be explored in a lightweight way as part
of this research and warrants further exploration and testing. Ideally
this type of framework would enable there to be more feedback more
quickly on core usability issues that impact human rights defenders,
rather than trying to cover as much as possible with limited access and
time.</p>
<h3 id="increased-research-sharing">Increased Research Sharing</h3>
<p>While we do not believe an open community is the right approach for
this region at this time, we do feel that smaller invite-only targeted
events, and intentional share-out sessions have potential. Operating in
smaller targeted events, allows for simpler and more manageable vetting
processes to be in-place, while also create space for
knowledge-sharing.</p>
<p>Additionally, we believe that selected sanitized research can and
should be shared within the larger internet freedom / public interest
technology communities as well.</p>
<p>Finally it is our belief that it the deeper user research and
usability experience work that is needed for tools to be adapted for use
in China, and that such research also needs to be tool specific. It is
nuanced. It is specialized. And such work will take creative
collaborative thinking. Therefore, we think long-term user experience
work can and should be done with each tool group individually;
increasing security and the likelihood of the features working for
China. Information and research sharing is going to continue to be
limited by the available collaboration tools, illuminating that this is
a critical barrier to continue to work to address.</p>
<h3
id="regional-expertise-and-professional-level-user-experience-research-need-to-be-prioritized-over-engineering">Regional
Expertise and Professional-Level User Experience Research need to be
prioritized over Engineering</h3>
<p>The models of funding and effective support for this region must be
rethought. Funding has prioritized the time and investment of
engineering costs, over investment in a) user experience expertise, b)
defenders’ time and expertise, and c) expertise of non-software NGOs
with standing in the region.</p>
<p>This is a common problem. Software stakeholders routinely expect NGOs
and activists’ networks (i.e., the ones taking the most risk in this
work) to participate in software development cycles without any
compensation. This is true, even if the projects’ funding and success
relies almost entirely on the use of the software by high-risk
individuals. Software stakeholders appear to operate under the
assumption these individuals should give their time for free, because a
tool that <em>might</em> be completed and <em>might end up</em> working
for the region is compensation enough (and even though as previously
noted these projects have no accountability or obligation to verify that
high risk defenders needs are actually met).</p>
<p>These issues speak to both challenges due to a lack of
standardization around practices. Organizations and teams could benefit
from best practices or support and resources to implement additional
procedures; and some of the requirements may be too overwrought for an
organization’s larger mission due to tensions with funding models,
compliance and reporting needs</p>
<p>One opportunity would be to standardize a practice of applying
security assessment tools, e.g. threat modeling, to the open source
software practices, particularly participant engagement, rather than
just the open source code. From our conversations with participants,
this did not appear to be a common practice. Leveraging a design and
evaluation practice around feedback processes and community engagement
practices could help bring visibility to these tensions and enable
software teams to consider processes and practices that might better
support high-risk users.</p>
<h3 id="training-for-targeted-software-stakeholders">Training for
Targeted Software Stakeholders</h3>
<p>The public interest security software ecosystem has been investing in
late stage user experience work, and largely left out very important
systems design thinking and user research that is needed to make
successful system. Yet these stages are vital for complex design
thinking.</p>
<p>In addition, the user experience professionals that participated in
this project—justifiably or not—suffer from a sense they cannot provide
insight and thinking on security issues. However, user experience and
appropriate threat modeling are inherently intwined for China. For these
reasons, it is recommended that the public interest software stakeholder
ecosystem invest in training user experience individuals for:</p>
<ul>
<li><p>Formal analytical assessment and research</p></li>
<li><p>Cybersecurity certificates</p></li>
</ul>
<p>We do not believe this recommendation requires extensive development
to implement. There are already many professional certifications and
professional training that could meet the level needed to “level-up”
user experience professionals working in this field. Though, it would
require funding and resourcing.</p>
<p>Combined with increased access to regional expertise, there is the
opportunity to apply the threat analysis skillsets with the increased
socio-political knowledge and better understand how to engage and
develop interventions for the region.</p>
<h3 id="additional-funder-specific-recommendations">Additional Funder
Specific Recommendations</h3>
<p>In addition to the ideas we’ve highlighted coming out of this
research, we also believe funders could then increase success by:</p>
<ul>
<li><p>Ensure trained, experienced product owners and research analysts
are required on projects;</p></li>
<li><p>Ensure these product owners and research analysts on software
projects are derived from NGOs (and other organizations) that have
“boots-on-the-ground”</p></li>
<li><p>Ensure that funded software projects have some viable mechanism
to measure success of meeting China defenders’ needs; and that such
needs are defined by defenders</p></li>
<li><p>Pay for regular region-specific “market” research of the security
software ecosystem</p></li>
<li><p>Ensure realistic funding is dedicated to the work of members of
defender networks and participating China-focused NGOs</p></li>
<li><p>Engage in region appropriate security models to support grantees
working in the region.</p></li>
</ul>
<h2 id="conclusion"><strong>Conclusion</strong></h2>
<p>Starting in 2020, this project set out with two objectives: (1) to
identity opportunities to network, support and cultivate learning
between activists in China, non-Chinese technologists and the global
internet governance community, and (2) to identify pathways of
recommendation to empower Chinese human rights defenders to participate
in broader international exchanges of information and collaboration. In
phase 1, the project explored the ecosystem to better understand the
needs and challenges towards these objections, and in phase 2, it
explored a specific gap in knowledge by testing a pilot framework for
facilitating feedback and information sharing among members of the
community focused on tools that enable collaboration and information
sharing. We found that before collaborative hubs can be considered or
attempted there needs to be a focus on basic user needs that enable safe
communication and collaboration, and there needs to be investment in
training and capacity building in the field as a whole to safely engage
in the region.</p>

<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
	<li id="fn1"><p><a href="https://www.theguardian.com/world/2022/aug/31/xi-jinping-poised-to-further-consolidate-power-at-party-congress">https://www.theguardian.com/world/2022/aug/31/xi-jinping-poised-to-further-consolidate-power-at-party-congress</a><a
	href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
	<li id="fn2"><p><a
	href="http://peres.rihmlab.org/Classes/PSYC6419seminar/p206-Five%20Users%20nielsen.pdf">http://peres.rihmlab.org/Classes/PSYC6419seminar/p206-Five%20Users%20nielsen.pdf</a><a
	href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
	<li id="fn3"><p><a href="https://freedomhouse.org/report/beijing-global-media-influence/2022/authoritarian-expansion-power-democratic-resilience">https://freedomhouse.org/report/beijing-global-media-influence/2022/authoritarian-expansion-power-democratic-resilience</a><a
	href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</div>

<div class="col-2"></div>

<hr class="pageChange">
  		
  	<div class="row">

  		<div class="col-2"></div>

  		<div class="col-8">
			<h2>Sharing</h2>
  			
  			<p>We use the Traffic Light Protocol (TLP) and designate this report as
			<h5>TLP:AMBER</h5>
  			Please only share the information with those members of your organization who need to know.</p>

  			<address class="reportContact">
				DUCT team<br>
				<a href="mailto:projectduct@proton.me">projectduct@proton.me</a><br>
			</address>
			<a href="/"><button type="button">Home</button></a> 

  		</div>

  		<div class="col-2"></div>

  	</div>

<img src="assets/svg/backpage2.svg">

</div>
</body>
</html>